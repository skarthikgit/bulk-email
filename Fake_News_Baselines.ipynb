{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/skarthikgit/bulk-email/blob/main/Fake_News_Baselines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment to install\n",
        "#!pip install tensorflow-text"
      ],
      "metadata": {
        "id": "nGD2amj_qHs6"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "oVyol0t-qJnI",
        "outputId": "09b313ab-c4c6-4315-9c95-d3fb31b07cd5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -ltr /content/drive/MyDrive/Fake_news/"
      ],
      "metadata": {
        "id": "9wIDmxn4rIMu",
        "outputId": "5754c58c-a713-45e3-ece3-ee1e776fe4f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 10713\n",
            "-rw------- 1 root root 10969548 Aug 29  2020 news_articles.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -ltr /content/drive/MyDrive/Fake_news/news_articles.csv"
      ],
      "metadata": {
        "id": "TDFeLcPErIJ4",
        "outputId": "ed266deb-7e5d-4b66-b395-e0ee3c232a58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-rw------- 1 root root 10969548 Aug 29  2020 /content/drive/MyDrive/Fake_news/news_articles.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install optuna"
      ],
      "metadata": {
        "id": "8dUOslgYm1BB",
        "outputId": "24f8ae99-2517-4d0a-955d-a8d8429c876e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optuna\n",
            "  Downloading optuna-4.1.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting alembic>=1.5.0 (from optuna)\n",
            "  Downloading alembic-1.14.0-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting colorlog (from optuna)\n",
            "  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from optuna) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna) (24.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.10/dist-packages (from optuna) (2.0.36)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from optuna) (4.67.1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from optuna) (6.0.2)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna)\n",
            "  Downloading Mako-1.3.8-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.1.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.10/dist-packages (from Mako->alembic>=1.5.0->optuna) (3.0.2)\n",
            "Downloading optuna-4.1.0-py3-none-any.whl (364 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.4/364.4 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.14.0-py3-none-any.whl (233 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.5/233.5 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n",
            "Downloading Mako-1.3.8-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: Mako, colorlog, alembic, optuna\n",
            "Successfully installed Mako-1.3.8 alembic-1.14.0 colorlog-6.9.0 optuna-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "xOggfCRHlZeb"
      },
      "outputs": [],
      "source": [
        "#importing basic libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Suppress Optuna logs\n",
        "optuna.logging.set_verbosity(optuna.logging.WARNING)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/Fake_news/news_articles.csv')"
      ],
      "metadata": {
        "id": "1obANRdNqL4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.tail(10)"
      ],
      "metadata": {
        "id": "J5Un6a8ZrNJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe()"
      ],
      "metadata": {
        "id": "wx7ehSGDB0q5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.info()"
      ],
      "metadata": {
        "id": "nGW0u3Q_B3d0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "id": "mxvaVWF1B6q7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Preparation and Mining"
      ],
      "metadata": {
        "id": "eTrTTNJlCVcr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#check for null values\n",
        "data.isnull().sum()"
      ],
      "metadata": {
        "id": "l_Gwv9HGCQwf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop the null values\n",
        "df.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "wbZ2tlODChgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Date Time split to see if any trend\n",
        "timesplit = df['published'].str.split('T', 1, expand=True)\n",
        "df['Time']=timesplit[1]\n",
        "df['Date']=timesplit[0]"
      ],
      "metadata": {
        "id": "Q_wO_9vtCc9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Split the Month and Day Data\n",
        "#Since all our data in from 2016, we might be able to see a trend if any, through the months\n",
        "datesplit = df['Date'].str.split('-',n=-1, expand=True)\n",
        "df['Year']=datesplit[0]\n",
        "df['Month']=datesplit[1]\n",
        "df['Day']=datesplit[2]"
      ],
      "metadata": {
        "id": "L1LMeUWYc3PY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#drop some error producing rows\n",
        "df.loc[df.Month == 'content/uploads/2014/04/jucundus']\n",
        "df.drop(848, inplace=True)\n",
        "df.loc[df.Month == 'content/uploads/2015/07/Earth']\n",
        "df.drop(1838, inplace=True)"
      ],
      "metadata": {
        "id": "zUchrWJXDT7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Change the type for ease of plotting\n",
        "df = df.astype({\"Month\": float, \"Day\":float})"
      ],
      "metadata": {
        "id": "hkjx7gU5DYNa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail(5)\n",
        "#cleaner and transformed data"
      ],
      "metadata": {
        "id": "K-Q6uukCDayY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Labelize the label column\n",
        "#Create Dummies to represent Real and Fake by 1 and 0\n",
        "dum_type=pd.get_dummies(df.label,drop_first=True,prefix=\"\")\n",
        "df=df.join(dum_type)\n",
        "df.drop('label', axis=1, inplace=True)\n",
        "df.rename(columns={'_Real':'Real'}, inplace=True)"
      ],
      "metadata": {
        "id": "xybZR_CUDccV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###EDA"
      ],
      "metadata": {
        "id": "7mw6ylqfDgMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#plot to see Counts of Real and Fake data\n",
        "sb.set_theme(style=\"whitegrid\")\n",
        "ax = sb.countplot(x=\"Real\", data=df, palette='Set3')\n",
        "ax.set_title(\"Count of Real and Fake Data\")"
      ],
      "metadata": {
        "id": "kTyIGLq9DfTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot to see Counts of Language data\n",
        "sb.set_theme(style=\"whitegrid\")\n",
        "ax = sb.countplot(x=\"language\", data=df, palette='Set3')\n",
        "ax.set_title(\"Count of Languages of the news\")"
      ],
      "metadata": {
        "id": "EGCViwobDkrH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot to see Counts of type of news data\n",
        "sb.set_theme(style=\"whitegrid\")\n",
        "ax = sb.countplot(x=\"type\", data=df, palette='Set3')\n",
        "ax.set_title(\"Count of Type of the news\")"
      ],
      "metadata": {
        "id": "nT9WdJsGDliI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot to see Counts news data that have images or no\n",
        "sb.set_theme(style=\"whitegrid\")\n",
        "ax = sb.countplot(x=\"hasImage\", data=df, palette='Set3')\n",
        "ax.set_title(\"Count of news with Images\")"
      ],
      "metadata": {
        "id": "Jc05DAoGEQZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot to see top 10 Authors with most news articles\n",
        "sb.set_theme(style=\"whitegrid\")\n",
        "ax = sb.countplot(y=\"author\", data=df, palette='Set3', order =df.author.value_counts().iloc[:10].index)\n",
        "ax.set_title(\"Top 10 Authors with count of news\")"
      ],
      "metadata": {
        "id": "6TPufWvTERVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot to see top 10 Authors with most news urls\n",
        "sb.set_theme(style=\"whitegrid\")\n",
        "ax = sb.countplot(y=\"site_url\", data=df, palette='Set3', order =df.site_url.value_counts().iloc[:10].index)\n",
        "ax.set_title(\"Top 10 Site URLS with count of news\")"
      ],
      "metadata": {
        "id": "qL4asD--ET8b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot to see Months of pblished news\n",
        "sb.set_theme(style=\"whitegrid\")\n",
        "ax = sb.countplot(x=\"Month\", data=df, palette='Set3')\n",
        "ax.set_title(\"Months of published news\")"
      ],
      "metadata": {
        "id": "W7_VrfCaEYOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot to see Days of pblished news\n",
        "sb.set_theme(style=\"whitegrid\")\n",
        "ax = sb.countplot(x=\"Day\", data=df, palette='Set3')\n",
        "sb.set(rc = {'figure.figsize':(10,10)})\n",
        "ax.set_title(\"Days of published news\")"
      ],
      "metadata": {
        "id": "pO0WzMvlEaKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fake Authors\n",
        "df.loc[df.Real == 0].author.value_counts().head(10)"
      ],
      "metadata": {
        "id": "f-xElD9hEdaB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fake URL sites\n",
        "df.loc[df.Real == 0].site_url.value_counts().head(10)"
      ],
      "metadata": {
        "id": "BQ1xvlWqEedr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Real Authors\n",
        "df.loc[df.Real == 1].author.value_counts().head(10)"
      ],
      "metadata": {
        "id": "m9XYc1i8Egyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Real URL sites\n",
        "df.loc[df.Real == 1].site_url.value_counts().head(10)"
      ],
      "metadata": {
        "id": "AHLbNGRZEjIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "real = set(df[df['Real'] == 1]['site_url'].unique())\n",
        "fake = set(df[df['Real'] == 0]['site_url'].unique())\n",
        "print(f\"{real & fake}\")"
      ],
      "metadata": {
        "id": "RzJI_60QElG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Feature Engineering"
      ],
      "metadata": {
        "id": "vf1OmvPIEnkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#target is our column to be predicted and features are the columns that we will use for modelling\n",
        "target = df.Real\n",
        "features = df[['author','site_url','text_without_stopwords']]"
      ],
      "metadata": {
        "id": "7biLvWQ0EpcE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features"
      ],
      "metadata": {
        "id": "HYI0B3tyErcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#since all the feature columns are text data, we want to use text mining techniques, we put all of them in the same column for ease of processing\n",
        "features['combined_url_text'] = features[\"author\"]+\" \"+features[\"site_url\"] + \" \" + features[\"text_without_stopwords\"]\n",
        "features.drop(['author','site_url', 'text_without_stopwords'], axis = 1, inplace = True)\n",
        "features=features.combined_url_text"
      ],
      "metadata": {
        "id": "sDiUZQI2Etbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features"
      ],
      "metadata": {
        "id": "TL92LKHUEv-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###TFID Vectorizer"
      ],
      "metadata": {
        "id": "LxihFVAkEzur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer_words = TfidfVectorizer(stop_words='english')\n",
        "X = vectorizer_words.fit_transform(features)"
      ],
      "metadata": {
        "id": "0BUjSsx7Ex9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trying to cluster the 2 data centres ie fake and real news\n",
        "from sklearn.cluster import KMeans\n",
        "km = KMeans(n_clusters = 2, init = 'k-means++', max_iter = 100, n_init = 1, verbose = True)\n",
        "km.fit(X)"
      ],
      "metadata": {
        "id": "y10TnVxUE3z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "np.unique(km.labels_, return_counts=True)\n",
        "features.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "eoPCnb7oE6YH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we are collecting all the fake data into one cluster and all the real data into another.\n",
        "#We are doing this as a pre step to the coming logic.\n",
        "text={}\n",
        "for i,cluster in enumerate(km.labels_):\n",
        "    oneDocument = features[i]\n",
        "    if cluster not in text.keys():\n",
        "        text[cluster] = oneDocument\n",
        "    else:\n",
        "        text[cluster] += oneDocument"
      ],
      "metadata": {
        "id": "12dkBfnTFdkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#importing NLTK libraries for NLP techiniques\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "from string import punctuation\n",
        "from heapq import nlargest\n",
        "import nltk"
      ],
      "metadata": {
        "id": "duSmuRuhFeqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#here we are finding the keywords that appear in both the clusters and we do not want to include the stop words as those will be the most frequent\n",
        "_stopwords = set(stopwords.words('english') + list(punctuation))\n",
        "\n",
        "keywords = {}\n",
        "counts={}\n",
        "for cluster in range(2):\n",
        "    word_sent = word_tokenize(text[cluster].lower())\n",
        "    word_sent=[word for word in word_sent if word not in _stopwords]\n",
        "    freq = FreqDist(word_sent)\n",
        "    keywords[cluster] = nlargest(100, freq, key=freq.get)\n",
        "    counts[cluster]=freq"
      ],
      "metadata": {
        "id": "tSSJX-9TFh-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keywords"
      ],
      "metadata": {
        "id": "VQKZNo3CFj6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#here we are finding keyword that are uniques to each cluster\n",
        "set0 = set(keywords[0])\n",
        "set1 = set(keywords[1])\n",
        "unique0=set0-set1\n",
        "unique1 =set1-set0"
      ],
      "metadata": {
        "id": "foKAtAaEFmrP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_keys={}\n",
        "unique_keys[0]=nlargest(10, unique0, key=counts[0].get)\n",
        "unique_keys[1]=nlargest(10, unique1, key=counts[1].get)"
      ],
      "metadata": {
        "id": "ssepNqFGFnQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_keys"
      ],
      "metadata": {
        "id": "qWHUdbxnFo66"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Modelling and Prediction"
      ],
      "metadata": {
        "id": "TtvqkivmFsv1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#using the Vectorizer before doing the classification\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train,X_test,y_train,y_test=train_test_split(features,target,test_size=0.20)\n",
        "\n",
        "vectorizer = TfidfVectorizer(stop_words = 'english')\n",
        "tfidf_train = vectorizer.fit_transform(X_train)\n",
        "tfidf_test = vectorizer.transform(X_test)\n",
        "tfidf_df = pd.DataFrame(tfidf_train.A, columns=vectorizer.get_feature_names())"
      ],
      "metadata": {
        "id": "e2qFVuOXFrlQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tfidf_train.shape)\n",
        "print(y_train.shape)"
      ],
      "metadata": {
        "id": "NdfPy2ftFysv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "# Initialize the KNeighborsClassifier with n_neighbors=5\n",
        "KNb = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "KNb.fit(tfidf_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = KNb.predict(tfidf_test)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "KNscore = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Generate the classification report\n",
        "classification_report = metrics.classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy score and the classification report\n",
        "print(f\"Accuracy Score: {KNscore}\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report)"
      ],
      "metadata": {
        "id": "Wz5n6cbmF00p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "# Initialize the RandomForestClassifier with n_estimators=1000\n",
        "RF = RandomForestClassifier(n_estimators=1000)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "RF.fit(tfidf_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = RF.predict(tfidf_test)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "RFscore = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Generate the classification report\n",
        "classification_report = metrics.classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy score and the classification report\n",
        "print(\"Random Forest Model accuracy: %0.4f\" % RFscore)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report)"
      ],
      "metadata": {
        "id": "kzt-VMrjZITB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "# Initialize the AdaBoostClassifier with a base DecisionTreeClassifier (max_depth=10) and n_estimators=5\n",
        "Adab = AdaBoostClassifier(DecisionTreeClassifier(max_depth=10), n_estimators=5)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "Adab.fit(tfidf_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = Adab.predict(tfidf_test)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "ABscore = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Generate the classification report\n",
        "classification_report = metrics.classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy score and the classification report\n",
        "print(\"AdaBoost Classifier accuracy: %0.4f\" % ABscore)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report)"
      ],
      "metadata": {
        "id": "8F5BJl1bZLYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn import metrics\n",
        "\n",
        "# Initialize the LogisticRegression model\n",
        "LR = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "LR.fit(tfidf_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = LR.predict(tfidf_test)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "LRscore = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Generate the classification report\n",
        "classification_report = metrics.classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy score and the classification report\n",
        "print(\"Logistic Regression accuracy: %0.4f\" % LRscore)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report)"
      ],
      "metadata": {
        "id": "G6SwV3FSZN65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn import metrics\n",
        "\n",
        "# Initialize the Support Vector Machine model\n",
        "SVM = SVC(kernel='linear')\n",
        "\n",
        "# Train the classifier on the training data\n",
        "SVM.fit(tfidf_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = SVM.predict(tfidf_test)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "SVMscore = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Generate the classification report\n",
        "classification_report = metrics.classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy score and the classification report\n",
        "print(\"Support Vector Machine accuracy: %0.4f\" % SVMscore)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report)"
      ],
      "metadata": {
        "id": "xkqi4oEmp2wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn import metrics\n",
        "\n",
        "# Initialize the Naive Bayes model\n",
        "NB = MultinomialNB()\n",
        "\n",
        "# Train the classifier on the training data\n",
        "NB.fit(tfidf_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = NB.predict(tfidf_test)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "NBscore = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Generate the classification report\n",
        "classification_report = metrics.classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy score and the classification report\n",
        "print(\"Naive Bayes accuracy: %0.4f\" % NBscore)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report)"
      ],
      "metadata": {
        "id": "y12zQTu-p30H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "# Initialize the DecisionTreeClassifier model\n",
        "DT = DecisionTreeClassifier(max_depth=10)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "DT.fit(tfidf_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = DT.predict(tfidf_test)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "DTscore = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Generate the classification report\n",
        "classification_report = metrics.classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy score and the classification report\n",
        "print(\"Decision Tree accuracy: %0.4f\" % DTscore)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report)"
      ],
      "metadata": {
        "id": "6iUYngnKp61Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "# Initialize the MLPClassifier model\n",
        "MLP = MLPClassifier(hidden_layer_sizes=(100,), max_iter=1000)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "MLP.fit(tfidf_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = MLP.predict(tfidf_test)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "MLPscore = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Generate the classification report\n",
        "classification_report = metrics.classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy score and the classification report\n",
        "print(\"MultiLayer Perceptron accuracy: %0.4f\" % MLPscore)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report)"
      ],
      "metadata": {
        "id": "3aQZKLsKp9dd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###GridSearchCV"
      ],
      "metadata": {
        "id": "GPG9dfVFqxuZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics\n",
        "\n",
        "# Initialize the LogisticRegression model\n",
        "LR = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {'C': [0.1, 1, 10]}\n",
        "\n",
        "# Initialize GridSearchCV with 2-fold cross-validation\n",
        "grid_search = GridSearchCV(LR, param_grid, cv=2)\n",
        "\n",
        "# Train the model with GridSearchCV\n",
        "grid_search.fit(tfidf_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = grid_search.predict(tfidf_test)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "LRscore = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Generate the classification report\n",
        "classification_report = metrics.classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy score, best parameters, and classification report\n",
        "print(\"Logistic Regression best parameters:\", grid_search.best_params_)\n",
        "print(\"Logistic Regression accuracy: %0.4f\" % LRscore)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report)"
      ],
      "metadata": {
        "id": "get74LDwqAca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics\n",
        "\n",
        "# Initialize the SVC model\n",
        "SVM = SVC()\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {'kernel': ['linear', 'rbf'], 'C': [0.1, 1, 10]}\n",
        "\n",
        "# Initialize GridSearchCV with 2-fold cross-validation\n",
        "grid_search = GridSearchCV(SVM, param_grid, cv=2)\n",
        "\n",
        "# Train the model with GridSearchCV\n",
        "grid_search.fit(tfidf_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = grid_search.predict(tfidf_test)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "SVMscore = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Generate the classification report\n",
        "classification_report = metrics.classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy score, best parameters, and classification report\n",
        "print(\"SVM best parameters:\", grid_search.best_params_)\n",
        "print(\"SVM accuracy: %0.4f\" % SVMscore)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report)"
      ],
      "metadata": {
        "id": "eDUhZZqDq-W4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics\n",
        "\n",
        "# Initialize the Naive Bayes model\n",
        "NB = MultinomialNB()\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {'alpha': [0.1, 1, 10]}\n",
        "\n",
        "# Initialize GridSearchCV with 2-fold cross-validation\n",
        "grid_search = GridSearchCV(NB, param_grid, cv=2)\n",
        "\n",
        "# Train the model with GridSearchCV\n",
        "grid_search.fit(tfidf_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = grid_search.predict(tfidf_test)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "NBscore = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Generate the classification report\n",
        "classification_report = metrics.classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy score, best parameters, and classification report\n",
        "print(\"Naive Bayes best parameters:\", grid_search.best_params_)\n",
        "print(\"Naive Bayes accuracy: %0.4f\" % NBscore)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report)"
      ],
      "metadata": {
        "id": "Zeh8ZPHVrRJw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics\n",
        "\n",
        "# Initialize the DecisionTreeClassifier model\n",
        "DT = DecisionTreeClassifier()\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {'max_depth': [5, 10, 15], 'min_samples_split': [2, 10]}\n",
        "\n",
        "# Initialize GridSearchCV with 2-fold cross-validation\n",
        "grid_search = GridSearchCV(DT, param_grid, cv=2)\n",
        "\n",
        "# Train the model with GridSearchCV\n",
        "grid_search.fit(tfidf_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = grid_search.predict(tfidf_test)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "DTscore = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Generate the classification report\n",
        "classification_report = metrics.classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy score, best parameters, and classification report\n",
        "print(\"Decision Tree best parameters:\", grid_search.best_params_)\n",
        "print(\"Decision Tree accuracy: %0.4f\" % DTscore)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report)"
      ],
      "metadata": {
        "id": "WCUvyduQrQ9d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn import metrics\n",
        "\n",
        "# Initialize the MLPClassifier model\n",
        "MLP = MLPClassifier(max_iter=1000)\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {'hidden_layer_sizes': [(50,), (100,), (100, 100)], 'activation': ['relu', 'tanh']}\n",
        "\n",
        "# Initialize GridSearchCV with 2-fold cross-validation\n",
        "grid_search = GridSearchCV(MLP, param_grid, cv=2)\n",
        "\n",
        "# Train the model with GridSearchCV\n",
        "grid_search.fit(tfidf_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = grid_search.predict(tfidf_test)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "MLPscore = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Generate the classification report\n",
        "classification_report = metrics.classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy score, best parameters, and classification report\n",
        "print(\"MultiLayer Perceptron best parameters:\", grid_search.best_params_)\n",
        "print(\"MultiLayer Perceptron accuracy: %0.4f\" % MLPscore)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report)"
      ],
      "metadata": {
        "id": "5DrWQdxmrVk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###RandomizedSearchCV"
      ],
      "metadata": {
        "id": "F5NV6V8oruVH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn import metrics\n",
        "\n",
        "# Initialize the LogisticRegression model\n",
        "LR = LogisticRegression(max_iter=1000)\n",
        "\n",
        "# Define the hyperparameter distribution\n",
        "param_dist = {'C': [0.1, 1, 10, 100], 'solver': ['liblinear', 'saga']}\n",
        "\n",
        "# Initialize RandomizedSearchCV with 2-fold cross-validation\n",
        "random_search = RandomizedSearchCV(LR, param_dist, n_iter=10, cv=2)\n",
        "\n",
        "# Train the model with RandomizedSearchCV\n",
        "random_search.fit(tfidf_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = random_search.predict(tfidf_test)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "LRscore = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Generate the classification report\n",
        "classification_report = metrics.classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy score, best parameters, and classification report\n",
        "print(\"Logistic Regression best parameters:\", random_search.best_params_)\n",
        "print(\"Logistic Regression accuracy: %0.4f\" % LRscore)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report)"
      ],
      "metadata": {
        "id": "-8LJMr_erQ5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn import metrics\n",
        "\n",
        "# Initialize the SVC model\n",
        "SVM = SVC()\n",
        "\n",
        "# Define the hyperparameter distribution\n",
        "param_dist = {'kernel': ['linear', 'rbf'], 'C': [0.1, 1, 10, 100], 'gamma': ['scale', 'auto']}\n",
        "\n",
        "# Initialize RandomizedSearchCV with 2-fold cross-validation\n",
        "random_search = RandomizedSearchCV(SVM, param_dist, n_iter=10, cv=2)\n",
        "\n",
        "# Train the model with RandomizedSearchCV\n",
        "random_search.fit(tfidf_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = random_search.predict(tfidf_test)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "SVMscore = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Generate the classification report\n",
        "classification_report = metrics.classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy score, best parameters, and classification report\n",
        "print(\"SVM best parameters:\", random_search.best_params_)\n",
        "print(\"SVM accuracy: %0.4f\" % SVMscore)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report)"
      ],
      "metadata": {
        "id": "-YSFX7wNrxPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn import metrics\n",
        "\n",
        "# Initialize the Naive Bayes model\n",
        "NB = MultinomialNB()\n",
        "\n",
        "# Define the hyperparameter distribution\n",
        "param_dist = {'alpha': [0.1, 0.5, 1, 2, 10]}\n",
        "\n",
        "# Initialize RandomizedSearchCV with 2-fold cross-validation\n",
        "random_search = RandomizedSearchCV(NB, param_dist, n_iter=5, cv=2)\n",
        "\n",
        "# Train the model with RandomizedSearchCV\n",
        "random_search.fit(tfidf_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = random_search.predict(tfidf_test)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "NBscore = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Generate the classification report\n",
        "classification_report = metrics.classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy score, best parameters, and classification report\n",
        "print(\"Naive Bayes best parameters:\", random_search.best_params_)\n",
        "print(\"Naive Bayes accuracy: %0.4f\" % NBscore)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report)"
      ],
      "metadata": {
        "id": "B01sOdjrr0Cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn import metrics\n",
        "\n",
        "# Initialize the DecisionTreeClassifier model\n",
        "DT = DecisionTreeClassifier()\n",
        "\n",
        "# Define the hyperparameter distribution\n",
        "param_dist = {'max_depth': [5, 10, 15, 20], 'min_samples_split': [2, 10, 20]}\n",
        "\n",
        "# Initialize RandomizedSearchCV with 2-fold cross-validation\n",
        "random_search = RandomizedSearchCV(DT, param_dist, n_iter=10, cv=2)\n",
        "\n",
        "# Train the model with RandomizedSearchCV\n",
        "random_search.fit(tfidf_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = random_search.predict(tfidf_test)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "DTscore = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Generate the classification report\n",
        "classification_report = metrics.classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy score, best parameters, and classification report\n",
        "print(\"Decision Tree best parameters:\", random_search.best_params_)\n",
        "print(\"Decision Tree accuracy: %0.4f\" % DTscore)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report)"
      ],
      "metadata": {
        "id": "n69qR3w4r39p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn import metrics\n",
        "\n",
        "# Initialize the MLPClassifier model\n",
        "MLP = MLPClassifier(max_iter=1000)\n",
        "\n",
        "# Define the hyperparameter distribution\n",
        "param_dist = {'hidden_layer_sizes': [(50,), (100,), (100, 100)], 'activation': ['relu', 'tanh']}\n",
        "\n",
        "# Initialize RandomizedSearchCV with 2-fold cross-validation\n",
        "random_search = RandomizedSearchCV(MLP, param_dist, n_iter=5, cv=2)\n",
        "\n",
        "# Train the model with RandomizedSearchCV\n",
        "random_search.fit(tfidf_train, y_train)\n",
        "\n",
        "# Predict the labels for the test data\n",
        "y_pred = random_search.predict(tfidf_test)\n",
        "\n",
        "# Calculate the accuracy score\n",
        "MLPscore = metrics.accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Generate the classification report\n",
        "classification_report = metrics.classification_report(y_test, y_pred)\n",
        "\n",
        "# Print the accuracy score, best parameters, and classification report\n",
        "print(\"MultiLayer Perceptron best parameters:\", random_search.best_params_)\n",
        "print(\"MultiLayer Perceptron accuracy: %0.4f\" % MLPscore)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report)"
      ],
      "metadata": {
        "id": "YJycnfQkr6WY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h2DpNJ_qr9TV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}